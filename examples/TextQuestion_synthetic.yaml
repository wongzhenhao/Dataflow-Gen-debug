meta_path: data/text/prompts.jsonl
base_folder: text_intermediate_results/
save_folder: results/text_generator
image_key: image # key for the image in the meta data
text_key: prompt # key for the text in the meta data
video_key: video # key for the video in the meta data

steps:
# example 2: using local model
  - type: TextGenerator
    name: LocalModelGenerator 
    config:
      device: "cuda" # device to run the model on
      model_path: "Qwen/Qwen2.5-1.5B-Instruct" # path to the local model
      n: 1 # number of generated sequences
      best_of: null  # best of sampling
      presence_penalty: 0  # presence penalty
      frequency_penalty: 0  # frequency penalty
      repetition_penalty: 1  # repetition penalty
      temperature: 1 # temperature for sampling
      top_p: 1 # top-p sampling
      top_k: -1 # top-k sampling
      min_p: 0 # minimum probability
      seed: null # random seed
      stop: null # stop sequence
      stop_token_ids: null # stop token ids
      ignore_eos: False
      max_tokens: 32
      min_tokens: 0
      logprobs: null
      prompt_logprobs: null
      detokenize: True
      skip_special_tokens: True
      spaces_between_special_tokens: True
      logits_processors: null
      include_stop_str_in_output: False
      truncate_prompt_tokens: null
      logit_bias: null # Dict[int,float]
      allowed_token_ids: null  # List[int]
      download_dir: "ckpr/models/"
      prompt: "You are a helpful assistant" #system prompt for the model

  
